{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suitable-olympus",
   "metadata": {},
   "source": [
    "# GCP BigQueryのマニュアルを実行したログ\n",
    "\n",
    "%load_ext マジック コマンドを使用して、BigQuery 用 IPython マジック コマンドを読み込みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-commitment",
   "metadata": {},
   "source": [
    "\n",
    "- 実行日 2021/3/24\n",
    "\n",
    "condaコマンドでインストールするとモジュールが古すぎでエラーが出る。そのため、pipコマンドのインストールじゃないと動かない。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-reverse",
   "metadata": {},
   "source": [
    "以下を実行しておくこと\n",
    "```\n",
    "export GOOGLE_APPLICATION_CREDENTIALS=[json]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "original-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alert-primary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.73s: 100%|██████████| 2/2 [00:00<00:00, 167.03query/s]                         \n",
      "Downloading: 100%|██████████| 294019/294019 [00:53<00:00, 5526.34rows/s] \n"
     ]
    }
   ],
   "source": [
    "%%bigquery tax_forms --use_bqstorage_api\n",
    "SELECT * FROM `bigquery-public-data.irs_990.irs_990_2012`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "substantial-skating",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 2/2 [00:00<00:00, 422.20query/s]                         \n",
      "Downloading: 100%|██████████| 10/10 [00:03<00:00,  2.80rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery stackoverflow --use_bqstorage_api\n",
    "SELECT\n",
    "  CONCAT(\n",
    "    'https://stackoverflow.com/questions/',\n",
    "    CAST(id as STRING)) as url,\n",
    "  view_count\n",
    "FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "WHERE tags like '%google-bigquery%'\n",
    "ORDER BY view_count DESC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liable-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.bigquery.magics\n",
    "\n",
    "google.cloud.bigquery.magics.context.use_bqstorage_api = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hairy-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 270.91query/s]\n",
      "Downloading: 100%|██████████| 294019/294019 [00:29<00:00, 10073.71rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery tax_forms\n",
    "SELECT * FROM `bigquery-public-data.irs_990.irs_990_2012`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-working",
   "metadata": {},
   "source": [
    "## Pythonクライアントライブラリを使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "improving-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.auth\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage\n",
    "\n",
    "# Explicitly create a credentials object. This allows you to use the same\n",
    "# credentials for both the BigQuery and BigQuery Storage clients, avoiding\n",
    "# unnecessary API calls to fetch duplicate authentication tokens.\n",
    "credentials, your_project_id = google.auth.default(\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "\n",
    "# Make clients.\n",
    "bqclient = bigquery.Client(credentials=credentials, project=your_project_id,)\n",
    "bqstorageclient = bigquery_storage.BigQueryReadClient(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indie-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            url  view_count\n",
      "0  https://stackoverflow.com/questions/35159967       88467\n",
      "1  https://stackoverflow.com/questions/10604135       84288\n",
      "2  https://stackoverflow.com/questions/22879669       82252\n",
      "3  https://stackoverflow.com/questions/27060396       65883\n",
      "4  https://stackoverflow.com/questions/11057219       62127\n"
     ]
    }
   ],
   "source": [
    "# Download query results.\n",
    "query_string = \"\"\"\n",
    "SELECT\n",
    "CONCAT(\n",
    "    'https://stackoverflow.com/questions/',\n",
    "    CAST(id as STRING)) as url,\n",
    "view_count\n",
    "FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "WHERE tags like '%google-bigquery%'\n",
    "ORDER BY view_count DESC\n",
    "\"\"\"\n",
    "\n",
    "dataframe = (\n",
    "    bqclient.query(query_string)\n",
    "    .result()\n",
    "    .to_dataframe(bqstorage_client=bqstorageclient)\n",
    ")\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sufficient-details",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country_name fips_code\n",
      "0          Akrotiri        AX\n",
      "1   Bassas da India        BS\n",
      "2          Dhekelia        DX\n",
      "3     Europa Island        EU\n",
      "4  Glorioso Islands        GO\n"
     ]
    }
   ],
   "source": [
    "# Download a table.\n",
    "table = bigquery.TableReference.from_string(\n",
    "    \"bigquery-public-data.utility_us.country_code_iso\"\n",
    ")\n",
    "rows = bqclient.list_rows(\n",
    "    table,\n",
    "    selected_fields=[\n",
    "        bigquery.SchemaField(\"country_name\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"fips_code\", \"STRING\"),\n",
    "    ],\n",
    ")\n",
    "dataframe = rows.to_dataframe(bqstorage_client=bqstorageclient)\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "naval-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "#マニュアルにこの記述、書いていないような。\n",
    "from google.cloud.bigquery_storage import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adequate-title",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species_common_name fall_color\n",
      "0         Shingle Oak     Yellow\n",
      "1          Tulip Tree     Yellow\n",
      "2    Northern Red Oak     Maroon\n",
      "3          Coffeetree     Yellow\n",
      "4            Sweetgum     Yellow\n"
     ]
    }
   ],
   "source": [
    "project_id = \"bigquery-public-data\"\n",
    "dataset_id = \"new_york_trees\"\n",
    "table_id = \"tree_species\"\n",
    "table = f\"projects/{project_id}/datasets/{dataset_id}/tables/{table_id}\"\n",
    "\n",
    "# Select columns to read with read options. If no read options are\n",
    "# specified, the whole table is read.\n",
    "read_options = types.ReadSession.TableReadOptions(\n",
    "    selected_fields=[\"species_common_name\", \"fall_color\"]\n",
    ")\n",
    "\n",
    "parent = \"projects/{}\".format(your_project_id)\n",
    "\n",
    "requested_session = types.ReadSession(\n",
    "    table=table,\n",
    "    # This API can also deliver data serialized in Apache Avro format.\n",
    "    # This example leverages Apache Arrow.\n",
    "    data_format=types.DataFormat.ARROW,\n",
    "    read_options=read_options,\n",
    ")\n",
    "read_session = bqstorageclient.create_read_session(\n",
    "    parent=parent, read_session=requested_session, max_stream_count=1,\n",
    ")\n",
    "\n",
    "# This example reads from only a single stream. Read from multiple streams\n",
    "# to fetch data faster. Note that the session may not contain any streams\n",
    "# if there are no rows to read.\n",
    "stream = read_session.streams[0]\n",
    "reader = bqstorageclient.read_rows(stream.name)\n",
    "\n",
    "# Parse all Arrow blocks and create a dataframe. This call requires a\n",
    "# session, because the session contains the schema for the row blocks.\n",
    "dataframe = reader.to_dataframe(read_session)\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "heated-dallas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-proof",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}